{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "\n",
    "TKIPDATA=\"./\"\n",
    "\n",
    "def read_file(f):\n",
    "    lines = f.read().splitlines()\n",
    "    return lines\n",
    "\n",
    "def pos_analysis(lst, ws, pos, ner):\n",
    "    word_sentence_list = ws(lst, sentence_segmentation=True)\n",
    "    pos_sentence_list = pos(word_sentence_list)\n",
    "    \n",
    "    return(word_sentence_list, pos_sentence_list)\n",
    "\n",
    "def print_pos(sentence_list, word_sentence_list,  pos_sentence_list, ofp):\n",
    "    for i, sentence in enumerate(sentence_list):\n",
    "        #print(sentence, word_sentence_list[i],  pos_sentence_list[i])\n",
    "        print_word_pos_sentence(sentence_list, word_sentence_list[i],  pos_sentence_list[i], ofp)\n",
    "\n",
    "# Show results\n",
    "def print_word_pos_sentence(sentence_list, word_sentence_list, pos_sentence_list, ofp):\n",
    "    assert len(word_sentence_list) == len(pos_sentence_list)\n",
    "    for word, pos in zip(word_sentence_list, pos_sentence_list):\n",
    "        print(f\"{word}({pos})\", end=\"\\u3000\")\n",
    "        ofp.write(f\"{word}({pos}) \")\n",
    "    print()\n",
    "    ofp.write(\"\\n\")\n",
    "\n",
    "def tkip_data():\n",
    "    #if not os.path.isdir(TKIPDATA):\n",
    "    print(\"Downloading CKIP data...\")\n",
    "        # Download data\n",
    "        #os.makedirs(TKIPDATA)\n",
    "    data_utils.download_data(TKIPDATA)\n",
    "\n",
    "    print(\"Loading CKIP data...\")\n",
    "    # Load model\n",
    "    ws = WS(TKIPDATA+\"data\")\n",
    "    pos = POS(TKIPDATA+\"data\")\n",
    "    ner = NER(TKIPDATA+\"data\")\n",
    "    \n",
    "    return (ws, pos, ner)\n",
    "\n",
    "(ws, pos, ner) = tkip_data()\n",
    "\n",
    "while(True):\n",
    "    txtfile=input(\"Input text file: \")\n",
    "    posfile=os.path.splitext(txtfile)[0]+'.pos'\n",
    "    print(\"Input: \", txtfile, \"Output: \", posfile)\n",
    "    print()\n",
    "    \n",
    "    fp = open(txtfile, encoding=\"utf8\")\n",
    "    ofp= open(posfile, \"w\", encoding=\"utf8\")\n",
    "\n",
    "    lines = read_file(fp)\n",
    "    for l in lines:\n",
    "        print(l)\n",
    "\n",
    "    print(\"-----------------------------\")\n",
    "    (wl, pl) = pos_analysis(lines, ws, pos, ner)\n",
    "    print_pos(lines, wl, pl, ofp)\n",
    "\n",
    "    print(\"-----------DONE--------------\")\n",
    "    fp.close()\n",
    "    ofp.close()\n",
    "\n",
    "# Release model\n",
    "del ws\n",
    "del pos\n",
    "del ner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
