{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\"\"\" Usage:\n",
    "    python3 thai14.py directory\n",
    "    \n",
    "    This file takes a directory, process all .textgrid file and output output 14-tier txtgrid file\n",
    "    directory: the directory that want to processed\n",
    "    \n",
    "    The output is textgrid_file+\".14\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from pypinyin import pinyin, lazy_pinyin, Style\n",
    "import pandas as pd\n",
    "import copy\n",
    "import glob\n",
    "import tgt\n",
    "from googletrans import Translator\n",
    "import itertools\n",
    "\n",
    "#讀入 EHowNet\n",
    "from ehownet_python3 import *\n",
    "\n",
    "def read_databases():\n",
    "    try:\n",
    "        #讀入字典\n",
    "        cdict = pd.read_excel('cdict_cond.xlsx')\n",
    "        #cdict.drop_duplicates(subset = None, keep = \"last\", inplace = True)\n",
    "        #print(dict)\n",
    "        \n",
    "        EHowTree=EHowNetTree(\"db/ehownet_ontology.sqlite\")\n",
    "        #tree=EHowNetTree(\"db/ehownet_ontology_sim.sqlite\")\n",
    "        #print(dict)\n",
    "        \n",
    "        zdf = pd.read_excel(\"zhuyin2ipa.xlsx\")\n",
    "    \n",
    "        return(cdict, EHowTree, zdf)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        exit(-1)\n",
    "\n",
    "(cdict, EHowTree, zdf) = read_databases()\n",
    "\n",
    "def contains_chinese(check_str):\n",
    "    \"\"\"\n",
    "    判断字符串中是否包含中文\n",
    "    :param check_str: {str} 需要检测的字符串\n",
    "    :return: {bool} 包含返回True， 不包含返回False\n",
    "    \"\"\"\n",
    "    for ch in check_str:\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fff':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_ascii(check_str):\n",
    "     return all(ord(c) < 128 for c in check_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def remove_noises(tr):\n",
    "    for o in tr._objects:\n",
    "        if o.duration() < 0.01:\n",
    "            tr.delete_annotation_by_start_time(o.start_time)\n",
    "\n",
    "def filling_gaps(tr):\n",
    "    tr.start_time = 0\n",
    "    o = tr._objects[0]\n",
    "    if o.start_time != 0:\n",
    "        o.start_time = 0\n",
    "    o = tr._objects[-1]\n",
    "    if o.end_time != tr.end_time:\n",
    "        o.end_time = tr.end_time\n",
    "    #print(tr)\n",
    "    idx = len(tr._objects)\n",
    "    for i in range(1,idx):\n",
    "        if tr._objects[i].start_time != tr._objects[i-1].end_time:\n",
    "            tr._objects[i].start_time = tr._objects[i-1].end_time\n",
    "\n",
    "def align_tiers(wtr, ptr):\n",
    "    for w in wtr._objects:\n",
    "        wst = w.start_time\n",
    "        wet = w.end_time\n",
    "        pann = ptr.get_annotations_between_timepoints(w.start_time, w.end_time, False, False)\n",
    " \n",
    "        if len(pann) != 0:\n",
    "            if not math.isclose(wst, pann[0].start_time):\n",
    "                pann2 = ptr.get_annotations_between_timepoints(w.start_time, w.end_time, True, False)\n",
    "                pst1 = pann[0].start_time\n",
    "                pst2 = pann2[0].start_time\n",
    "                #print(\"S:\", w.start_time, pann[0].start_time, pann2[0].start_time)\n",
    "                if abs(wst - pst1) < abs(wst - pst2):\n",
    "                    pann[0].start_time = wst\n",
    "                else:\n",
    "                    pann2[0].start_time = wst\n",
    "\n",
    "            #print(\"Wet:\", math.isclose(wet, pann[-1].end_time), wet, pann[-1].end_time)\n",
    "            if  not math.isclose(wet, pann[-1].end_time):\n",
    "                pann2 = ptr.get_annotations_between_timepoints(w.start_time, w.end_time, False, True)\n",
    "                pet1 = pann[-1].end_time\n",
    "                pet2 = pann2[-1].end_time\n",
    "                #print(\"E: \", wet, pann[-1].end_time, pann2[-1].end_time)\n",
    "                if abs(wet - pet1) < abs(wet - pet2):\n",
    "                    pann[-1].end_time = wet\n",
    "                else:\n",
    "                    pann2[-1].end_time = wet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECZ1=['ㄓ','ㄔ','ㄕ','ㄖ','ㄗ','ㄘ','ㄙ']\n",
    "SPECZ2=['ㄧ','ㄨ','ㄩ']\n",
    "CSPECZ2=['i','u','y']\n",
    "FOURSOUNDS=['ˊ','ˇ','ˋ','˙']\n",
    "DUOZ=['ㄧㄢ','ㄩㄢ','ㄧㄣ','ㄧㄥ','ㄨㄥ','ㄩㄥ']\n",
    "\n",
    "def foursounds(c):\n",
    "    if 'ˋ' in c:\n",
    "        return \"51 \"\n",
    "    elif 'ˊ' in c:\n",
    "        return \"35 \"\n",
    "    elif 'ˇ' in c:\n",
    "        return \"21 \"\n",
    "    elif '˙' in c:\n",
    "        return \"0 \"\n",
    "    else:\n",
    "        return \"55 \"\n",
    "    \n",
    "def convertZH(zdf, zh):\n",
    "    #print(\"searching\", zh)\n",
    "    x = zdf[zdf['Zhuyin']==zh].IPA.to_string(index=False)\n",
    "    if x == \"Series([], )\":\n",
    "        return ''\n",
    "    else:\n",
    "        return x\n",
    "        #return x.replace(' ','')\n",
    "\n",
    "def remove_foursounds(zh):\n",
    "    z = zh\n",
    "    for f in FOURSOUNDS:\n",
    "        z = z.replace(f,'')\n",
    "    return z\n",
    "\n",
    "def is_duo(zh):\n",
    "    for d in DUOZ:\n",
    "        if d in zh:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def duo_convert(zdf, zh):\n",
    "    #print(\"zh0\",zh[0])\n",
    "    matching = False\n",
    "    for z in SPECZ2:\n",
    "        #print(\"zzh\", z, zh[0])\n",
    "        if z == zh[0]:\n",
    "            matching = True\n",
    "            break\n",
    "    \n",
    "    if matching:\n",
    "        #print(\"Converting zh\", zh)\n",
    "        return [convertZH(zdf, zh)]\n",
    "    else:\n",
    "        return [convertZH(zdf, zh[0]), convertZH(zdf, zh[1:]).replace('\\n','')]\n",
    "    \n",
    "def convertIUY(z, last):\n",
    "    if last:\n",
    "        if z == 'ㄧ':\n",
    "            return 'i'\n",
    "        elif z == 'ㄨ':\n",
    "            return 'u'\n",
    "        else:\n",
    "            return 'y'\n",
    "    else:\n",
    "        if z == 'ㄧ':\n",
    "            return 'j'\n",
    "        elif z == 'ㄨ':\n",
    "            return 'w'\n",
    "        else:\n",
    "            return 'ɥ'\n",
    "\n",
    "def zhuyin2ipa(zdf, zhuyin):\n",
    "    zh=remove_foursounds(zhuyin)\n",
    "    idx = 0\n",
    "    zhlen = len(zh)\n",
    "    \n",
    "    if is_duo(zh):\n",
    "        return(duo_convert(zdf, zh))\n",
    "    \n",
    "    IPAL=[]\n",
    "    while (idx < zhlen):\n",
    "        #print(idx)\n",
    "        if zh[idx] in SPECZ1:\n",
    "            if zhlen == 1:\n",
    "                return ([convertZH(zdf, zh[idx]), 'ɨ'])\n",
    "            else:\n",
    "                IPAL.append(convertZH(zdf, zh[idx]))\n",
    "                idx = idx + 1\n",
    "                \n",
    "        elif zh[idx] in SPECZ2:\n",
    "            if idx == zhlen - 1:\n",
    "                #The last one\n",
    "                lc = convertIUY(zh[idx], True)\n",
    "                IPAL.append(lc)\n",
    "                return IPAL\n",
    "            else:\n",
    "                lc = convertIUY(zh[idx], False)\n",
    "                IPAL.append(lc)\n",
    "                idx = idx + 1\n",
    "        else:\n",
    "            IPAL.append(convertZH(zdf, zh[idx]))\n",
    "            idx = idx + 1\n",
    "            \n",
    "    #print(IPAL)\n",
    "    return IPAL\n",
    "\n",
    "#zdf = read_zhuyin2upa_table()\n",
    "z=zhuyin2ipa(zdf, \" ㄗ˙\")\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[6]:\n",
    "SPLITLIST=['aj','ej','aw','ow','an','jɛn','ɥɛn','ən','in','aŋ','əŋ','iŋ','oŋ','joŋ']\n",
    "\n",
    "def iu_tier(iut, wt, name):\n",
    "    iut_tier = copy.deepcopy(iut)\n",
    "    iut_tier.name = name\n",
    "    #print(iut_tier)\n",
    "    for ann in iut_tier._objects:\n",
    "        #print(\">>\", ann.text)\n",
    "        if ann.text == \"\":\n",
    "            #print(ann.text, ann.start_time, ann.end_time)\n",
    "            annlist = wt.get_annotations_between_timepoints(ann.start_time, ann.end_time)\n",
    "            txt = \"\"\n",
    "            for itm in annlist:\n",
    "                txt = txt + itm.text\n",
    "            #print(txt)\n",
    "            ann.text = txt.replace(\"*\",\"\").replace(\"^\",\"\")\n",
    "            if 'sp' in ann.text and 'sp' != ann.text:\n",
    "                ann.text = ann.text.replace(\"sp\", \" \")\n",
    "    \n",
    "    #print(iut_tier)\n",
    "    return iut_tier\n",
    "\n",
    "def english_tier(iut, name, translator):\n",
    "    et_tier = copy.deepcopy(iut)\n",
    "    et_tier.name = name\n",
    "    mydict = {}\n",
    "    for a in et_tier._objects:\n",
    "        if (contains_chinese(a.text)): \n",
    "            print(\"Contains chinese:\", a.text)\n",
    "            tr = translator.translate(a.text, dest = 'en')\n",
    "            a.text = tr.text\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            print(a.text)\n",
    "    #print(et_tier)\n",
    "    return et_tier\n",
    "\n",
    "def word_tier(wt, name):\n",
    "    wt_tier = copy.deepcopy(wt)\n",
    "    wt_tier.name = name\n",
    "    for a in wt_tier._objects:\n",
    "        if (contains_chinese(a.text)): \n",
    "            newannstr = \"\"\n",
    "            #去 EHowNet 查詞性\n",
    "            posp=EHowTree.searchWord(a.text)\n",
    "            if posp:\n",
    "                for w in posp:\n",
    "                    #print(w.pos)\n",
    "                    newannstr = newannstr + w.pos + \" \"\n",
    "                #print(node)\n",
    "                a.text = newannstr.rstrip()\n",
    "            else:\n",
    "                a.text = \"\"\n",
    "        elif a.text != \"sp\":\n",
    "            a.text=\"\"\n",
    "    #print(wt_tier)\n",
    "    return wt_tier\n",
    "            \n",
    "def phone_tier(wt, name, zdf):\n",
    "    ph_tier = tgt.core.IntervalTier(wt.start_time, wt.end_time, name)\n",
    "    \n",
    "    for a in wt._objects:\n",
    "        if (contains_chinese(a.text)):\n",
    "            print(a.text, end=\" \")\n",
    "            cccl = []\n",
    "            for c in a.text:\n",
    "                ccl = pinyin(c, style=Style.BOPOMOFO)\n",
    "                #print(c, ccl[0][0], end=\" \")\n",
    "                cccl.append(ccl[0][0])\n",
    "\n",
    "                #convert zhuying into IPA\n",
    "                ipal = []\n",
    "                for uccl in cccl:\n",
    "                    #print(uccl)\n",
    "                    uipa = zhuyin2ipa(zdf, uccl)\n",
    "                    #print(uipa, end=\" \")\n",
    "                    #uuipa = [''.join(uipa[0:])]\n",
    "                    ipal.append(uipa)\n",
    "                \n",
    "            flat_list = list(itertools.chain.from_iterable(ipal))\n",
    "            flat_list= [f.replace(\" \",\"\") for f in flat_list]\n",
    "            #print(\"flat list\", flat_list)\n",
    "            fl2 = []\n",
    "            for f in flat_list:\n",
    "                #print(f, end = \" \")\n",
    "                if f in SPLITLIST:\n",
    "                    #print(\"In splitlist\")\n",
    "                    fl2.append(list(f))\n",
    "                else:\n",
    "                    fl2.append(f)\n",
    "            fl2 = [x for x in fl2 if x !='']\n",
    "            fl3 = []\n",
    "            for item in fl2:\n",
    "                if isinstance(item, list):\n",
    "                    for item2 in item:\n",
    "                        fl3.append(item2)\n",
    "                else:\n",
    "                    fl3.append(item)\n",
    "            #fl2 = flat_list = [item for sublist in fl2 for item in sublist]\n",
    "            print(fl3)\n",
    "            #flat_list = [i.replace(\" \", \"\") for i in flat_list if len(i) > 0]\n",
    "            tintv = (a.end_time - a.start_time)/len(fl3)\n",
    "            fstart = a.start_time\n",
    "            fend = fstart+tintv\n",
    "            for f in fl3:\n",
    "                pann = tgt.core.Annotation(fstart, fend, f)\n",
    "                ph_tier.add_annotation(pann)\n",
    "                fstart = fstart + tintv\n",
    "                fend = fend + tintv\n",
    "                \n",
    "        elif a.text == 'sp':\n",
    "            pann = tgt.core.Annotation(a.start_time, a.end_time, \"sp\")\n",
    "            ph_tier.add_annotation(pann)            \n",
    "        else:\n",
    "            pann = tgt.core.Annotation(a.start_time, a.end_time, \"\")\n",
    "            ph_tier.add_annotation(pann)\n",
    "    #print(ph_tier)  \n",
    "    return ph_tier\n",
    "\n",
    "def syllable_tier(wt, pt, name, zdf):\n",
    "    syl_tier = copy.deepcopy(wt)\n",
    "    syl_tier.name = name\n",
    "    \n",
    "    for a in syl_tier._objects:\n",
    "        if contains_chinese(a.text):\n",
    "            annlist=pt.get_annotations_between_timepoints(a.start_time, a.end_time)\n",
    "            cgvn=\"\"\n",
    "            for aa in annlist:\n",
    "                cgvn = cgvn + zdf[zdf['IPA']==aa.text].CGVN.to_string(index=False)\n",
    "            \n",
    "            a.text = cgvn.replace(\" \",\"\")\n",
    "        elif a.text == 'sp':\n",
    "            a.text = 'sp'\n",
    "\n",
    "    return syl_tier\n",
    "    \n",
    "def tone_tier(wt, name):\n",
    "    ttier = copy.deepcopy(wt)\n",
    "    ttier.name = name\n",
    "    for a in ttier._objects:\n",
    "        if (contains_chinese(a.text)):\n",
    "            cccl = []\n",
    "            for c in a.text: \n",
    "                ccl = pinyin(c, style=Style.BOPOMOFO)\n",
    "                cccl.append(ccl[0][0])\n",
    "            \n",
    "            pl = \"\"\n",
    "            for p in cccl:\n",
    "                pl = pl + foursounds(p) + \" \"\n",
    "            \n",
    "            a.text = pl.replace(\"  \", \" \").rstrip()\n",
    "        elif a.text != 'sp':\n",
    "            a.text = \"\"\n",
    "    print(ttier)\n",
    "    return ttier\n",
    "\n",
    "def type_tier(iust, name):\n",
    "    typetier = copy.deepcopy(iust)\n",
    "    typetier.name == name\n",
    "    for a in typetier._objects:\n",
    "        if \"*\" in a.text:\n",
    "            a.text = \"*\"\n",
    "        elif \"^\" in a.text:\n",
    "            a.text = \"^\"\n",
    "        elif a.text != 'sp':\n",
    "            a.text = \"\"\n",
    "            \n",
    "    return typetier\n",
    "\n",
    "def subject_tier(wt, name):\n",
    "    subtier = copy.deepcopy(wt)\n",
    "    subtier.name == name\n",
    "    for a in subtier._objects:\n",
    "        if a.text != 'sp':\n",
    "            a.text = \"\"\n",
    "    return subtier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In[9]:\n",
    "\n",
    "def parse_tiers(tg):\n",
    "    iutier = tg.get_tier_by_name(\"IU/teacher\")\n",
    "    wstier = tg.get_tier_by_name(\"Word/teacher\")\n",
    "    iutone = tg.get_tier_by_name(\"IU/student\")\n",
    "    eutone = tg.get_tier_by_name(\"Word/student\")\n",
    "    return iutier, wstier, iutone, eutone\n",
    "\n",
    "# Two tiers from original textgrid file\n",
    "\n",
    "def thai14_main(txtgridr):\n",
    "    #print(txtgridr)\n",
    "    txtlist = glob.glob(txtgridr+\"/*.TextGrid\")\n",
    "    print(\"File list\", txtlist)\n",
    "    #translator = Translator()\n",
    "    #print(translator)\n",
    "    for txtgridf in txtlist:\n",
    "        tg = tgt.io.read_textgrid(txtgridf, encoding='utf-8', include_empty_intervals=True)\n",
    "        iuteacher, wordteacher, iustudent, wordstudent = parse_tiers(tg)\n",
    "        #print(iuteacher)\n",
    "        #print(wordteacher)\n",
    "        #print(iustudent)\n",
    "        #print(wordstudent)\n",
    "        #for t in [iuteacher, wordteacher, iustudent, wordstudent]:\n",
    "        #    remove_noises(t)\n",
    "        #    filling_gaps(t)\n",
    "\n",
    "        #align_tiers(wordtier, phonetier)\n",
    "\n",
    "        st = tg.start_time\n",
    "        et = tg.end_time\n",
    "\n",
    "        #Construct tier contents\n",
    "        new_iu_teacher = iu_tier(iuteacher, wordteacher, \"IU/teacher\") \n",
    "        new_english_teacher = english_tier(new_iu_teacher, \"English/teacher\", translator) \n",
    "        new_word_teacher = word_tier(wordteacher, \"Word/teacher\")\n",
    "        new_iu_phone = phone_tier(wordteacher, \"IU/phone\", zdf)\n",
    "        new_iu_syllable = syllable_tier(wordteacher, new_iu_phone, \"IU/syllable\", zdf)\n",
    "        new_iu_tone = tone_tier(wordteacher, \"IU/tone\")\n",
    "        new_iu_student = iu_tier(iustudent, wordstudent, \"IU/student\")\n",
    "        new_english_student = english_tier(new_iu_student, \"English/student\")\n",
    "        new_word_student = word_tier(wordstudent, \"Word/student\")\n",
    "        new_eu_phone = phone_tier(wordstudent, \"IU/student\", zdf)\n",
    "        new_eu_syllable = syllable_tier(wordstudent, new_eu_phone, \"EU/syllable\", zdf)\n",
    "        new_eu_tone = tone_tier(wordstudent, \"EU/tone\")\n",
    "        new_eu_type = type_tier(iustudent, \"EU/type\")\n",
    "        new_subject = subject_tier(new_iu_student, \"Subject\")\n",
    "        \n",
    "        # Construct textgrid\n",
    "        newtg = tgt.core.TextGrid()        \n",
    "        for nt in [new_iu_teacher, \n",
    "                   new_english_teacher, \n",
    "                   new_word_teacher, \n",
    "                   new_iu_phone, \n",
    "                   new_iu_syllable, \n",
    "                   new_iu_tone, \n",
    "                   new_iu_student, \n",
    "                   new_english_student,\n",
    "                   new_word_student, \n",
    "                   new_eu_phone, \n",
    "                   new_eu_syllable, \n",
    "                   new_eu_tone, \n",
    "                   new_eu_type,\n",
    "                   new_subject\n",
    "                  ]:\n",
    "            newtg.add_tier(nt)\n",
    "\n",
    "        tgt.io.write_to_file(newtg, txtgridf+\".14\", format=\"long\")\n",
    "\n",
    "\n",
    "#thai14_main(\"./\")\n",
    "\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    if (len(sys.argv) != 2):\n",
    "        print(\"Parameter error\")\n",
    "        print(__doc__)\n",
    "        sys.exit(-1)\n",
    "    else:\n",
    "        txtgridr = sys.argv[1]\n",
    "        thai14_main(txtgridr)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
